{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST con PyTorch: CPU vs GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "MNIST es una dataset de dígitos escritos a mano (disponible en http://yann.lecun.com/exdb/mnist/). Tiene un conjunto de entrenamiento de 60.000 ejemplos y un conjunto de prueba de 10.000 ejemplos. Es un subconjunto de un conjunto más grande disponible en NIST. Los dígitos se normalizaron en tamaño y se centraron en una imagen de tamaño fijo.\n",
    "\n",
    "Según sus autores, es una buena base de datos para las personas que desean probar técnicas de aprendizaje y métodos de reconocimiento de patrones en datos del mundo real mientras dedican un esfuerzo mínimo al preprocesamiento y formato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "El uso de Deep Learning ha crecido enormemente en los últimos años con el aumento de GPU, big data, proveedores de nube como Amazon Web Services (AWS) y Google Cloud, y frameworks como Torch, TensorFlow, Caffe y PyTorch. Además, las grandes empresas comparten algoritmos entrenados en enormes conjuntos de datos, lo que ayuda a las nuevas empresas a construir sistemas de vanguardia en varios casos de uso con poco esfuerzo.\n",
    "\n",
    "Con PyTorch, al igual que con otros frameworks, una vez que tengamos los datos en forma de tensores, podemos hacer operaciones como suma, resta, multiplicación, producto escalar y multiplicación de matrices. Todas estas operaciones es posible realizarlas con el uso de la CPU o en la GPU. PyTorch proporciona una función simple llamada `cuda` para copiar un tensor de la CPU a la GPU.\n",
    "\n",
    "PyTorch utiliza ampliamente conceptos de Python, como clases, estructuras y bucles condicionales, lo que nos permite construir algoritmos DL de una manera puramente orientada a objetos. La mayoría de los otros marcos populares traen su propio estilo de programación, lo que a veces dificulta la escritura de nuevos algoritmos y no admite la depuración intuitiva.\n",
    "\n",
    "Echaremos un vistazo a algunas de las operaciones y compararemos el rendimiento entre las operaciones de multiplicación de matrices en la CPU y la GPU, para luego, comparar el rendimiento al entrenar una red neuronal utilizando el dataset MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intalación del driver NVidia, Cuda y PyTorch correspondiente\n",
    "\n",
    "Una vez realizada una introducción es hora de irnos a una parte más técnica y específica. Trataré de mencionar o describir algunos pasos que pudieran convertirse en una ayuda para otras personas que comienzan en este mundo. Me permitiré hacerlo de una forma menos formal y más directa, al fin al cabo esto no es más que un resumen de las horas y GBs (paquetes de 2.5 GB LTE que brida ETECSA) invertidos en aras de tener un ecosistema listo para trabajar.\n",
    "\n",
    "Partiré mencionando el hardware y software con los que cuento para luego resumir en una serie de pasos la instalación del driver NVidia, Cuda y PyTorch.\n",
    "\n",
    "Hardware:\n",
    "- CPU: Intel(R) Celeron(R) CPU G1830 @ 2.80GHz\n",
    "- RAM: 4GB DIMM DDR3 Synchronous 1333 MHz (0,8 ns)\n",
    "- GPU: GeForce GTX 780 Ti\n",
    "\n",
    "Sistema Operativo:\n",
    "- GNU/Linux (Linux Mint 19.1 https://linuxmint.com/) 64 bits\n",
    "\n",
    "Ya llega la hora de ir para arriba del lío y SI, a enfrentarnos al bloqueo. Estamos en presencia de una de los tantas dificultades que tenemos a causa del bloqueo: descargar el driver correspondiente a nuestra tarjeta de video. Lo sencillo y normal sería ir a https://www.nvidia.com/Download/index.aspx pero ahí solo encontraremos un `Access Denied. You don't have permission to access \"http://www.nvidia.com/Download/index.aspx\" on this server.` Por lo tanto me redirijo a una VPN y descago el archivo `NVIDIA-Linux-x86_64-410.93.run`. Lo otro es sencillo:\n",
    "\n",
    "- `$ sudo su`\n",
    "- `$ sh NVIDIA-Linux-x86_64-410.93.run`\n",
    "\n",
    "![](images/driver.png)\n",
    "\n",
    "Una vez ya instalado el driver sigo obligado a utilizar VPN para hacerme del archivo `cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb`. CUDA es una plataforma de computación paralela y un modelo de programación inventado por NVIDIA. Permite aumentos drásticos en el rendimiento informático al aprovechar la potencia de la unidad de procesamiento de gráficos (GPU).\n",
    "\n",
    "Al fin llegamos a PyTorch, por suerte aún nos permiten las descargas desde https://download.pytorch.org/whl/torch_stable.html, por lo que nos descargamos `torch-1.3.0+cu100-cp36-cp36m-linux_x86_64.whl` ya que tengo Python 3.6.7. No recomiendo instalar una versión más actualizada porque no funcionarán algunos codes a causa de la incompatibilidad con la GPU (GeForce GTX 780 Ti).\n",
    "\n",
    "Ahora sí. Listos para escribir código. Probemos si realmente estamos utilizando la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En efecto, si al ejecuar le aparece `cuda:0` estamos utilizando la GPU, de lo contrario, si le aparece `cpu` es porque solo se estaría utilizando la CPU.\n",
    "\n",
    "Ahora comparemos ambos casos al multiplicar 2 matrices de tensores y veamos los tiempos. Tenga en cuenta que cualquier tensor se puede mover a la GPU llamando a la función .cuda ()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dos matrices 10000 x 10000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10000, 10000)\n",
    "b = torch.rand(10000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multipliquemos `a` x `b` en la CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 52.0623407364 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "a.matmul(b)\n",
    "elapsed_time = time() - start_time\n",
    "print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mueva los tensores a la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0085325241 seconds.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    start_time = time()\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "    a.matmul(b)\n",
    "    elapsed_time = time() - start_time\n",
    "else:\n",
    "    print(\"Cuda not available\")\n",
    "print(\"Elapsed time: %0.10f seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta corrida la multiplicación de las matrices generadas en la CPU fue de 52 segundos, mientras que la GPU lo calculó en 0.4 segundos. Ummmmmm que interesante!!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que sucede al entrenar una red utilizando el dataset MNIST realizando solo 5 iteraciones (epochs).\n",
    "\n",
    "CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1138\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1962\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0515\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0622\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0561\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0321\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0760\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1218\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0151\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0569\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0924\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0084\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0275\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0058\n",
      "Epoch [3/5], Step [300/600], Loss: 0.1034\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1626\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0463\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0949\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0052\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0093\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0427\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0344\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0222\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0073\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0161\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0272\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0233\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0688\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0137\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0147\n",
      "Elapsed time (with CPU): 781.3217623234 seconds.\n",
      "Test Accuracy of the model on the 10000 test images: 99.04 %\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/mnist_data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/mnist_data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "elapsed_time = time() - start_time\n",
    "print(\"Elapsed time (with CPU): %0.10f seconds.\" % elapsed_time)\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.0821\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0578\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0206\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0725\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0339\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0549\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0266\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0145\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0972\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0338\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0581\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0249\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0145\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0591\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0166\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0322\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1136\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0233\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0272\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0026\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0017\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0166\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0114\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0673\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0147\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0331\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0172\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0025\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0079\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0115\n",
      "Elapsed time (with GPU): 46.4459891319 seconds.\n",
      "Test Accuracy of the model on the 10000 test images: 99.07 %\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/mnist_data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/mnist_data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "elapsed_time = time() - start_time\n",
    "print(\"Elapsed time (with GPU): %0.10f seconds.\" % elapsed_time)\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues sencillo, utilizando CPU algo más de 13 minutos y con la GPU menos de 1 minuto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
